{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "zaIxgIqPpZ4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO7P-z55pXXW"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c titanic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "train = pd.read_csv(\"train.csv\")"
      ],
      "metadata": {
        "id": "ORgtTHRPqryy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 150)\n"
      ],
      "metadata": {
        "id": "1npZw7fM0qA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test.columns.values)\n",
        "#['PassengerId' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare' 'Cabin' 'Embarked']\n",
        "print(train.columns.values)\n",
        "#['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare' 'Cabin' 'Embarked']\n",
        "print(len(test))"
      ],
      "metadata": {
        "id": "RxQRlofKM81E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove unnecessary data: \"ticket\"\n",
        "for df in [test,train]:\n",
        "  u_data = [\"Cabin\",\"Ticket\",\"Name\"]\n",
        "  for u in u_data:\n",
        "    df.drop(u,axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "LmEtm28_Nugw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.dropna(subset=['Fare','Embarked'],inplace=True)\n",
        "\n",
        "print( type(test['Fare'].isnull())    )\n",
        "print(type(test['Fare'].isnull().values))\n",
        "\n",
        "for s in ['Fare','Embarked']:\n",
        "  most_freq = test[s].value_counts().idxmax()\n",
        "  for c in range(len(test[s])):\n",
        "    if(test[s].isnull()[c]):\n",
        "      test[s][c] = most_freq\n",
        "\n",
        "#test.dropna(subset=['Fare','Embarked'],inplace=True)"
      ],
      "metadata": {
        "id": "J1tJ1qhfw5PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.sort_values(by=\"Age\",inplace=True)\n",
        "train['Age'] = train['Age'].interpolate(method='linear',limit_direction='forward',axis=0)\n",
        "#https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e\n",
        "\n",
        "test.sort_values(by=\"Age\",inplace=True)\n",
        "test['Age'] = test['Age'].interpolate(method='linear',limit_direction='forward',axis=0)\n",
        "#https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e"
      ],
      "metadata": {
        "id": "7fuaVr8T0hA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.dropna(subset=['Sex'])\n",
        "#test.dropna(subset=['Sex'])\n",
        "\n",
        "most_freq = test['Sex'].value_counts().idxmax()\n",
        "\n",
        "\n",
        "#https://datascienceparichay.com/article/most-frequent-value-in-a-pandas-column/\n",
        "for c in range(len(test['Sex'])):\n",
        "  if(test['Sex'].isnull().values[c]):\n",
        "    test['Sex'][c] = most_freq"
      ],
      "metadata": {
        "id": "8hjCLva6YSN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test['Sex'].value_counts())"
      ],
      "metadata": {
        "id": "ynZeMi_SaxVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.reset_index(drop=True,inplace=True)\n",
        "test.reset_index(drop=True,inplace=True)"
      ],
      "metadata": {
        "id": "9Zc8fbWTRLgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encode Sex\n",
        "\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "encoded_df = pd.DataFrame(encoder.fit_transform(train[['Sex']]).toarray())\n",
        "encoded_df.rename(columns={0:'Female',1:'Male'},inplace=True)\n"
      ],
      "metadata": {
        "id": "MKiUjdr93bIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop('Sex', axis=1)\n",
        "train = train.join(encoded_df)\n",
        "#print(train.isnull().sum())"
      ],
      "metadata": {
        "id": "KVTjOMhsceSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encode Sex\n",
        "\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "encoded_df = pd.DataFrame(encoder.fit_transform(test[['Sex']]).toarray())\n",
        "encoded_df.rename(columns={0:'Female',1:'Male'},inplace=True)\n",
        "\n",
        "test = test.drop('Sex', axis=1)\n",
        "test = test.join(encoded_df)\n"
      ],
      "metadata": {
        "id": "toB0MyZkUnPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "encoded_df = pd.DataFrame(encoder.fit_transform(train[['Embarked']]))\n",
        "\n",
        "train.drop('Embarked',axis=1,inplace=True)\n",
        "train = train.join(encoded_df)\n"
      ],
      "metadata": {
        "id": "kB5np2XdEHgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_df = pd.DataFrame(encoder.fit_transform(test[['Embarked']]))\n",
        "\n",
        "most_freq = test['Embarked'].value_counts().idxmax();\n",
        "for r in range(len(test)):\n",
        "  if(test['Embarked'].isnull()[r]):\n",
        "    test['Embarked'][r] = most_freq\n",
        "\n",
        "\n",
        "\n",
        "test.drop('Embarked',axis=1,inplace=True)\n",
        "test = test.join(encoded_df)"
      ],
      "metadata": {
        "id": "c1BvCdnaTI5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#handle null/NaN values\n",
        "\n",
        "for df in [test,train]:\n",
        "  print(\"-----------------------------------------\")\n",
        "  print(df.isnull().sum())\n",
        "  for c in df.columns.values:\n",
        "    print(df[[c]].isna().sum())\n",
        "\n",
        "\"\"\"\n",
        "test\n",
        "-----------------------------------------\n",
        "Age    86\n",
        "Fare    1\n",
        "\n",
        "train\n",
        "-----------------------------------------\n",
        "Age    177\n",
        "Embarked    2\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#Strategy: remove fare, embarked and fix age"
      ],
      "metadata": {
        "id": "RfMjdd8IMqH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier(n_neighbors=math.floor(math.sqrt(len(train))))\n",
        "#X is data, Y is label\n",
        "X = train.drop(columns=['Survived','PassengerId'])\n",
        "Y = train[['Survived']]\n",
        "\n",
        "model.fit(X,Y)\n",
        "model.score(X,Y)\n",
        "\n",
        "preds = model.predict(test.drop(columns=['PassengerId']))\n",
        "\n",
        "#0.63875"
      ],
      "metadata": {
        "id": "Zmg7gJrJaBrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "model = svm.SVC()\n",
        "X = train.drop(columns=['Survived','PassengerId'])\n",
        "Y = train[['Survived']]\n",
        "\n",
        "model.fit(X,Y)\n",
        "model.score(X,Y)\n",
        "\n",
        "preds = model.predict(test.drop(columns=['PassengerId']))\n",
        "\n",
        "#0.66985"
      ],
      "metadata": {
        "id": "CIQpVZRKWUcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "model = GaussianNB();\n",
        "X = train.drop(columns=['Survived','PassengerId'])\n",
        "Y = train[['Survived']]\n",
        "\n",
        "model.fit(X,Y)\n",
        "model.score(X,Y)\n",
        "\n",
        "preds = model.predict(test.drop(columns=['PassengerId']))\n",
        "\n",
        "#0.75119"
      ],
      "metadata": {
        "id": "FfjNaSK-l4yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)\n",
        "\n",
        "X = train.drop(columns=['Survived','PassengerId'])\n",
        "Y = train[['Survived']]\n",
        "Y = label_encoder.fit_transform(Y)\n",
        "\n",
        "model.fit(X,Y)\n",
        "model.score(X,Y)\n",
        "\n",
        "preds = model.predict(test.drop(columns=['PassengerId']))\n",
        "\n",
        "#0.75119"
      ],
      "metadata": {
        "id": "xeCyNAFvmT_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.DataFrame(columns=['PassengerId','Survived']);\n",
        "df['PassengerId'] = test['PassengerId']\n",
        "df['Survived'] = preds\n",
        "\n",
        "df.to_csv('data2.csv',index=False)\n",
        "!cp data.csv \"drive/My Drive/\""
      ],
      "metadata": {
        "id": "u4opdU2XiD_o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
